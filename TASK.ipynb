{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6220687c-27d6-4389-8f35-3dc5c1c522e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_data(base_dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    # Traverse through each subdirectory\n",
    "    for folder in os.listdir(base_dir):\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.endswith('.tif') and 'mask' not in filename:\n",
    "                    img_path = os.path.join(folder_path, filename)\n",
    "                    mask_path = os.path.join(folder_path, filename.replace('.tif', '_mask.tif'))\n",
    "                    \n",
    "                    # Check if corresponding mask exists\n",
    "                    if os.path.exists(mask_path):\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        \n",
    "                        images.append(img)\n",
    "                        masks.append(mask)\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Example usage\n",
    "base_dir = r'C:\\Users\\Suraj\\Downloads\\Data\\Data'\n",
    "images, masks = load_data(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f872c752-313c-4f4a-9aa2-8547a682545e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_clahe(image):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(image)\n",
    "\n",
    "images_clahe = np.array([apply_clahe(img) for img in images])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60891524-8b4a-4669-abbd-5acb1ff45de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_normalized = images_clahe / 255.0\n",
    "masks_normalized = masks / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3791f304-93f5-42c2-8a6b-4b49cd426cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "def augment_data(images, masks):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    return datagen.flow(images[..., np.newaxis], masks[..., np.newaxis], batch_size=32)\n",
    "\n",
    "augmented_data = augment_data(images_normalized, masks_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e4eb91-e692-4c71-92bd-04a712af3789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_normalized, masks_normalized, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b2a000c-3617-446e-bc8d-b75f1f75ca6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def nested_unet(input_shape):\n",
    "    inputs = layers.Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
    "    \n",
    "    output = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv2) \n",
    "    return Model(inputs, output)\n",
    "\n",
    "model_nested = nested_unet((256, 256, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "128553b0-1364-4a0c-a356-4a87107b4e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_nested.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdfd6597-e9ee-423e-91e9-9a74f1b10ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (51511296,) (12877824,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate on test data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m y_pred_nested \u001b[38;5;241m=\u001b[39m model_nested\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 10\u001b[0m dice_score_nested \u001b[38;5;241m=\u001b[39m \u001b[43mdice_coefficient\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_nested\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDICE Score Nested U-Net: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdice_score_nested\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m, in \u001b[0;36mdice_coefficient\u001b[1;34m(y_true, y_pred, smooth)\u001b[0m\n\u001b[0;32m      2\u001b[0m y_true_f \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m      3\u001b[0m y_pred_f \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m----> 4\u001b[0m intersection \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43my_true_f\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred_f\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m*\u001b[39m intersection \u001b[38;5;241m+\u001b[39m smooth) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39msum(y_true_f) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msum(y_pred_f) \u001b[38;5;241m+\u001b[39m smooth)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (51511296,) (12877824,) "
     ]
    }
   ],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "# Evaluate on test data\n",
    "y_pred_nested = model_nested.predict(X_test)\n",
    "\n",
    "dice_score_nested = dice_coefficient(y_test, y_pred_nested)\n",
    "\n",
    "print(f'DICE Score Nested U-Net: {dice_score_nested}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "983678de-39da-49f9-877b-2d9d480dcca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_nested = np.squeeze(y_pred_nested)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c144a84-f5c4-4e1d-b91b-4341d4253d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "y_pred_resized = [cv2.resize(pred, (256, 256), interpolation=cv2.INTER_NEAREST) for pred in y_pred_nested]\n",
    "y_pred_resized = np.array(y_pred_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21b96be2-3158-4998-b178-38254ae90b78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test shape: (786, 256, 256)\n",
      "y_pred_nested shape: (786, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"y_pred_nested shape: {y_pred_nested.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47f528-ef20-4ef2-9e51-176ebf6b3752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
